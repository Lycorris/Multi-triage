{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9544780-798f-4bf2-babe-5c804685346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import BCELoss\n",
    "from torch.optim import SGD, Adam\n",
    "from keras_preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm\n",
    "import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef1b744d-8f1d-41fa-b7b1-dbccc36d4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCodeDataset(Dataset):\n",
    "    def __init__(self, data_path, pad_seq_len, use_AST=True, classify_btype=True):\n",
    "        self.data_path = data_path\n",
    "        self.pad_seq_len = pad_seq_len\n",
    "        self.use_AST, self.classify_btype = use_AST, classify_btype\n",
    "        self.data_pd = pd.read_csv(data_path,\n",
    "                                   error_bad_lines=False, index_col=False, dtype='unicode', encoding='latin-1',\n",
    "                                   low_memory=False).sample(frac=1)\n",
    "        self.y_dev, self.y_btype = list(self.data_pd['FixedByID']), list(self.data_pd['Name'])\n",
    "        self.y_dev, self.y_btype = [str(x) for x in self.y_dev], [str(x) for x in self.y_btype]\n",
    "        self.y_dev, self.y_btype = [x.split('|') for x in self.y_dev], [x.split('|') for x in self.y_btype]\n",
    "\n",
    "        self.x_context, self.x_AST = list(self.data_pd['Title_Description']), list(self.data_pd['AST'])\n",
    "        self.x_context, self.x_AST = [str(x) for x in self.x_context], [str(x) for x in self.x_AST]\n",
    "\n",
    "    def tokenize_input(self, tokenizer_C: Tokenizer, tokenizer_A: Tokenizer):\n",
    "        self.x_context = tokenizer_C.texts_to_sequences(self.x_context)\n",
    "        self.x_AST = tokenizer_A.texts_to_sequences(self.x_AST)\n",
    "        self.x_context = pad_sequences(self.x_context, maxlen=self.pad_seq_len, padding='post')\n",
    "        self.x_AST = pad_sequences(self.x_AST, maxlen=self.pad_seq_len, padding='post')\n",
    "        self.x_context = torch.from_numpy(self.x_context)\n",
    "        self.x_AST = torch.from_numpy(self.x_AST)\n",
    "\n",
    "    def map_output(self, map_d: dict, map_b: dict):\n",
    "        tensor_d, tensor_b = torch.zeros((len(self.data_pd), len(map_d))), torch.zeros((len(self.data_pd), len(map_b)))\n",
    "        for i, ds in enumerate(self.y_dev):\n",
    "            for d in ds:\n",
    "                tensor_d[i][map_d[d]] = 1\n",
    "        for i, bs in enumerate(self.y_btype):\n",
    "            for b in bs:\n",
    "                tensor_b[i][map_b[b]] = 1\n",
    "        self.y_dev, self.y_btype = tensor_d, tensor_b\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        input = self.x_context[i], self.x_AST[i] if self.use_AST else self.x_context[i]\n",
    "        output = self.y_dev[i], self.y_btype[i] if self.classify_btype else self.y_dev[i]\n",
    "        return input, output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9ce4e8de-b5ae-4c07-bd09-15a6ee7e4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset_input(train_dataset: TextCodeDataset, test_dataset: TextCodeDataset):\n",
    "    tokenizer_C = Tokenizer()\n",
    "    tokenizer_C.fit_on_texts(train_dataset.x_context + test_dataset.x_context)\n",
    "    tokenizer_A = Tokenizer()\n",
    "    tokenizer_A.fit_on_texts(train_dataset.x_AST + test_dataset.x_AST)\n",
    "    train_dataset.tokenize_input(tokenizer_C, tokenizer_A)\n",
    "    test_dataset.tokenize_input(tokenizer_C, tokenizer_A)\n",
    "    return [len(tokenizer_C.word_index)+100, len(tokenizer_A.word_index)+100]\n",
    "\n",
    "\n",
    "def map_dataset_output(train_dataset: TextCodeDataset, test_dataset: TextCodeDataset):\n",
    "    set_d, set_b = set(), set()\n",
    "    for _ in range(len(train_dataset)):\n",
    "        for d in train_dataset.y_dev:\n",
    "            set_d.update(d)\n",
    "        for b in train_dataset.y_btype:\n",
    "            set_b.update(b)\n",
    "    for _ in range(len(test_dataset)):\n",
    "        for d in test_dataset.y_dev:\n",
    "            set_d.update(d)\n",
    "        for b in test_dataset.y_btype:\n",
    "            set_b.update(b)\n",
    "    labels_d, labels_b = list(set_d), list(set_b)\n",
    "    labels_d.sort(), labels_b.sort()\n",
    "    map_d, map_b = {labels_d[i]: i for i in range(len(labels_d))}, {labels_b[i]: i for i in range(len(labels_b))}\n",
    "    train_dataset.map_output(map_d, map_b)\n",
    "    test_dataset.map_output(map_d, map_b)\n",
    "    return labels_d, labels_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cab102b8-4e6c-47aa-8ecf-d24bc7afba08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alion\\AppData\\Local\\Temp\\ipykernel_18352\\2707828345.py:6: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  self.data_pd = pd.read_csv(data_path,\n",
      "C:\\Users\\Alion\\AppData\\Local\\Temp\\ipykernel_18352\\2707828345.py:6: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  self.data_pd = pd.read_csv(data_path,\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "# train_path = 'Data/powershell/C_uA_Train.csv'\n",
    "train_path = 'Data/powershell/C_uA_Train_withoutU.csv'\n",
    "# test_path = 'Data/aspnet/Nov10数据/IssueaspnetcoreWebScraptestdata5.csv'\n",
    "test_path = 'Data/powershell/C_uA_Test_withoutU.csv'\n",
    "MAX_SEQ_LEN = 300\n",
    "EMB_DIM = 100\n",
    "Learning_Rate = 3e-3\n",
    "EPOCH = 300\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "Weight_MSE, Weight_BCE = 0, 1\n",
    "# 0, 1.0, 1e-3, 100 -> 0.008\n",
    "# 0.1, 0.9, 1e-3, 100 -> 0.04\n",
    "# 0.2, 0.8, 1e-3, 100 -> 0.06\n",
    "# 0.3, 0.7, 1e-3, 100 -> 0.12\n",
    "# 0.4, 0.6, 1e-3, 100 -> 0.15\n",
    "# 0.5, 0.5, 1e-3, 100 -> 0.19\n",
    "# 0.6, 0.4, 1e-3, 100 -> 0.2\n",
    "# 0.7, 0.3, 1e-3, 100 -> 0.2, stable\n",
    "# 0.8, 0.2, 1e-3, 100 -> 0.2, convergence   | 0.07 simple model\n",
    "# 0.9, 0.1, 1e-3, 100 -> 0.15, convergence\n",
    "# 1, 0, 1e-3, 100 -> ~0\n",
    "train_dataset = TextCodeDataset(train_path, pad_seq_len=MAX_SEQ_LEN)\n",
    "test_dataset = TextCodeDataset(test_path, pad_seq_len=MAX_SEQ_LEN)\n",
    "\n",
    "vocab_size = tokenize_dataset_input(train_dataset, test_dataset)\n",
    "idx2label = map_dataset_output(train_dataset, test_dataset)\n",
    "num_out = [len(x) for x in idx2label]\n",
    "\n",
    "# dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f67d9a6",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7e9693d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Developer Type Label Counts:\n",
      "cormacpayne: 113\n",
      "markcowl: 88\n",
      "maddieclayton: 85\n",
      "miyanni: 46\n",
      "hyonholee: 38\n",
      "panchagnula: 33\n",
      "ravbhatnagar: 30\n",
      "bganapa: 24\n",
      "blueww: 23\n",
      "solankisamir: 23\n",
      "twitchax: 22\n",
      "singhkays: 21\n",
      "darshanhs90: 19\n",
      "viananth: 16\n",
      "akromm: 15\n",
      "gucalder: 14\n",
      "sergey-shandar: 14\n",
      "viverm: 12\n",
      "vrdmr: 11\n",
      " praries880: 10\n",
      "v-ajnava: 10\n",
      "hovsepm: 10\n",
      "vladimir-shcherbakov: 10\n",
      "shahabhijeet: 10\n",
      " maddieclayton: 9\n",
      "praries880: 8\n",
      "markjbrown: 7\n",
      " ganeshmsazure: 7\n",
      "huangpf: 7\n",
      "dragonfly91: 6\n",
      " dragav: 6\n",
      " eamonoreilly: 6\n",
      " tiano2017: 6\n",
      " miyanni: 6\n",
      "derek1ee: 6\n",
      " knithinc: 5\n",
      " safeermohammed: 5\n",
      " avkaur: 5\n",
      "sriramvu: 5\n",
      " panchagnula: 4\n",
      "matthchr: 4\n",
      "yaakoviyun: 4\n",
      "nking92: 4\n",
      " jaredmoo: 4\n",
      "siddharthchatrolams: 4\n",
      "ahmedelnably: 4\n",
      "danielsollondon: 4\n",
      " huangpf: 3\n",
      "jaredmoo: 3\n",
      " danielsollondon: 3\n",
      "niander: 3\n",
      "rkmanda: 3\n",
      " bganapa: 3\n",
      "rahuldutta90: 3\n",
      "gandhiniraj: 3\n",
      "vincent81-jiang: 3\n",
      "ms-premp: 3\n",
      "erich-wang: 3\n",
      " sdwheeler: 3\n",
      " cormacpayne: 3\n",
      "dragav: 3\n",
      "akshaysngupta: 3\n",
      " aim-for-better: 3\n",
      " singhkays: 3\n",
      "safeermohammed: 3\n",
      "chlahav: 2\n",
      "alpon: 2\n",
      "pattipaka: 2\n",
      " hyonholee: 2\n",
      "vivsriaus: 2\n",
      "mboersma: 2\n",
      "sdwheeler: 2\n",
      "am018: 2\n",
      "mikhailtryakhov: 2\n",
      "rohinkoul: 2\n",
      " thomasyip-msft: 2\n",
      " v-ajnava: 2\n",
      "irrogozh: 2\n",
      "idear1203: 2\n",
      " mkherani: 2\n",
      "asheniam: 2\n",
      " blueww: 2\n",
      "dcaro: 2\n",
      "vinjiang: 2\n",
      " gbowerman: 2\n",
      "schaabs: 2\n",
      "nilambari: 2\n",
      "finiteattractor: 2\n",
      "ericbourland: 2\n",
      " sphibbs: 2\n",
      "tiano2017: 2\n",
      " najams: 2\n",
      " chandrasekarsrinivasan: 2\n",
      " nitinbps: 2\n",
      " savyasachisamal: 2\n",
      "vikram-m: 2\n",
      " hvermis: 2\n",
      "felixwa: 2\n",
      " ahmedelnably: 2\n",
      " viverm: 2\n",
      " juhacket: 2\n",
      "eshaparmar: 2\n",
      "juhacket: 2\n",
      "polischuk: 1\n",
      "giladmit: 1\n",
      "veryearly: 1\n",
      "kirthik: 1\n",
      "filizt: 1\n",
      "vinatara: 1\n",
      "anton-evseev: 1\n",
      "ranisha2: 1\n",
      "devigned: 1\n",
      " anusapan: 1\n",
      "sourabhguha: 1\n",
      "sphibbs: 1\n",
      "roshankumarmicrosoft: 1\n",
      "ejarvi: 1\n",
      "vinisoto: 1\n",
      "wilcobmsft: 1\n",
      "cefranlly: 1\n",
      "haitch: 1\n",
      "emmazhu: 1\n",
      "btardif: 1\n",
      "wolfeno: 1\n",
      " solankisamir: 1\n",
      "isaacegglestone: 1\n",
      "nitinbps: 1\n",
      "artisticcheese: 1\n",
      "jagilber: 1\n",
      "mtandon80: 1\n",
      "alvipeo: 1\n",
      "itsramz: 1\n",
      "kduraira: 1\n",
      "kaushalp: 1\n",
      "lamchester: 1\n",
      "chhabaramesh: 1\n",
      "mattcowen: 1\n",
      "hothotsyu: 1\n",
      "dihan0604: 1\n",
      "imeya: 1\n",
      "xenalite: 1\n",
      "deathly809: 1\n",
      "siddharth7: 1\n",
      "vsadams: 1\n",
      "randallilama: 1\n",
      "mateusamin: 1\n",
      "ebmarquez: 1\n",
      " taiwu: 1\n",
      "matt1883: 1\n",
      "gmainar: 1\n",
      " matthchr: 1\n",
      "ritwikbasu: 1\n",
      "ankushbindlish2: 1\n",
      " viananth: 1\n",
      "imtiazh: 1\n",
      "somilganguly: 1\n",
      "brandonstiff: 1\n",
      " dedhar: 1\n",
      "paylocity-sflanders: 1\n",
      "abatishchev: 1\n",
      "isra-fel: 1\n",
      "toddrob: 1\n",
      "tlisiecki: 1\n",
      "arlevitt: 1\n",
      "mssedusch: 1\n",
      "neaggarwms: 1\n",
      " epkalyanr: 1\n",
      " anatolib: 1\n",
      "mosharafms: 1\n",
      "prasanna-padmanabhan: 1\n",
      "seguler: 1\n",
      " antoniowmsft: 1\n",
      "poetzelsbergerfranz: 1\n",
      "tomapaunovic: 1\n",
      "demyanenko: 1\n",
      " yaakoviyun: 1\n",
      "jillrebecca: 1\n",
      "davenewza: 1\n",
      "jasonmv: 1\n",
      "dingliu: 1\n",
      "jasonrshaver: 1\n",
      " niander: 1\n",
      "karravi-msft: 1\n",
      " grlin: 1\n",
      "zhangyd2015: 1\n",
      " ravbhatnagar: 1\n",
      "sndkr: 1\n",
      "blackbaud-shaydenofziger: 1\n",
      " rahuldutta90: 1\n",
      "gheibia: 1\n",
      " tassaduqbasu: 1\n",
      "mxplusb: 1\n",
      "claytonmartin: 1\n",
      "maximotrinidad: 1\n",
      " isra-fel: 1\n",
      "hvermis: 1\n",
      "a-santamaria: 1\n",
      "kwill-msft: 1\n",
      "georgeedwards: 1\n",
      "liadlev: 1\n",
      "ggirard07: 1\n",
      "ganeshmsazure: 1\n",
      "thejachoudary: 1\n",
      " chagarw: 1\n",
      "intotskie: 1\n",
      "allencal: 1\n",
      "maboja-msft: 1\n",
      " ryanvog: 1\n",
      "kringen: 1\n",
      "ruslany: 1\n",
      " kevinblasko: 1\n",
      "d1v38om83r: 1\n",
      "claudiafergus: 1\n",
      "djyou: 1\n",
      " kirthik: 1\n",
      " madsd: 1\n",
      "v-tisheg: 1\n",
      " sneivandt: 1\n",
      "tarjei99: 1\n",
      "ravilolam: 1\n",
      "jamestao: 1\n",
      "nimishas: 1\n",
      "naveenkumarjagtab: 1\n",
      " gucalder: 1\n",
      "zhiweiv: 1\n",
      "leowumsft: 1\n",
      " veryearly: 1\n",
      "eosho: 1\n",
      "kotasudhakarreddy: 1\n",
      "jrgithub: 1\n",
      "avkaur: 1\n",
      "bholzmmc: 1\n",
      " markcowl: 1\n",
      "pixia: 1\n",
      "\n",
      "Bug Type Label Counts:\n",
      " service attention: 375\n",
      "azure ps team: 170\n",
      " netcore: 51\n",
      " engineering: 37\n",
      "more info label: 32\n",
      " investigate mag: 32\n",
      " bug: 30\n",
      " more info label: 28\n",
      " storage: 27\n",
      " feature-request: 26\n",
      " automation-dsc: 20\n",
      " doc - reference: 19\n",
      "module bootstrapper: 15\n",
      " azure ps team: 14\n",
      " doc - internal: 13\n",
      " versioning: 12\n",
      " service bus: 9\n",
      " compute: 9\n",
      " resource authorization: 8\n",
      " compute - vm: 8\n",
      " customer experience: 7\n",
      "versioning: 7\n",
      " ramp up: 7\n",
      " network: 6\n",
      " first week: 6\n",
      " service fabric: 6\n",
      " arm - core: 6\n",
      " ps1xml: 5\n",
      " question: 5\n",
      " pull request open: 5\n",
      " multi-sprint: 5\n",
      "experiment microscope: 4\n",
      "investigate mag: 4\n",
      " network - application gateway: 4\n",
      " module bootstrapper: 4\n",
      " icm related item: 3\n",
      " azure stack: 3\n",
      " recovery services backup: 3\n",
      " automation-cheetah: 3\n",
      " automation-modules: 3\n",
      " customer-reported: 2\n",
      "storage: 2\n",
      "api management: 2\n",
      "doc - internal: 2\n",
      " network - traffic manager: 2\n",
      " network - network watcher: 2\n",
      "azure stack: 2\n",
      "keyvault: 2\n",
      " customer-response-expected: 2\n",
      " doc - conceptual: 2\n",
      " compute - extensions: 2\n",
      "netcore: 2\n",
      " p0: 1\n",
      " subscription: 1\n",
      " experiment microscope: 1\n",
      " monitor: 1\n",
      " batch: 1\n",
      "doc - conceptual: 1\n",
      " app services: 1\n",
      " automation-leads: 1\n",
      " network - expressroute: 1\n",
      " network - load balancer: 1\n",
      " compute - managed disks: 1\n",
      " automation-elephant: 1\n",
      " redis cache: 1\n",
      " recovery services site-recovery: 1\n",
      " test debt: 1\n",
      " network - dns: 1\n",
      "network: 1\n",
      " automation-pm: 1\n",
      "app services: 1\n",
      "service attention: 1\n",
      " strategy library: 1\n",
      " automation: 1\n",
      " scheduler: 1\n",
      " convenience: 1\n",
      " recovery services: 1\n",
      " pairing: 1\n",
      "rdfe: 1\n",
      " generator: 1\n",
      " compute - vmss: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO : data augmentation\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "def one_hot_to_indices(one_hot_array):\n",
    "    indices = np.argmax(one_hot_array, axis=1)\n",
    "    return indices\n",
    "\n",
    "# 获取所有的标签\n",
    "y_dev_labels = train_dataset.y_dev\n",
    "y_btype_labels = train_dataset.y_btype\n",
    "\n",
    "# print('y_dev_labels:', y_dev_labels[:1])\n",
    "# print('y_btype_labels:', y_btype_labels[:1])\n",
    "# print('len(y_dev_labels[0]):', len(y_dev_labels[0])) # number of developer types\n",
    "# print('len(y_btype_labels[0]):', len(y_btype_labels[0])) #  number of bug types\n",
    "\n",
    "# 使用你的独热编码数组调用函数\n",
    "indices_dev = one_hot_to_indices(y_dev_labels.numpy())\n",
    "# print(indices_dev)\n",
    "indices_btype = one_hot_to_indices(y_btype_labels.numpy())\n",
    "# print(indices_btype)\n",
    "\n",
    "dev_idx2label = {i: idx2label[0][i] for i in range(len(idx2label[0]))}\n",
    "btype_idx2label = {i: idx2label[1][i] for i in range(len(idx2label[1]))}\n",
    "\n",
    "# 计算每个标签的出现次数\n",
    "dev_label_counts = Counter(indices_dev)\n",
    "btype_label_counts = Counter(indices_btype)\n",
    "\n",
    "# 获取排序的键值对\n",
    "dev_label_counts_sorted = dev_label_counts.most_common()\n",
    "btype_label_counts_sorted = btype_label_counts.most_common()\n",
    "\n",
    "# 打印出现次数排行\n",
    "print('Developer Type Label Counts:')\n",
    "for label, count in dev_label_counts_sorted:\n",
    "    print(f'{dev_idx2label[label]}: {count}')\n",
    "\n",
    "print('\\nBug Type Label Counts:')\n",
    "for label, count in btype_label_counts_sorted:\n",
    "    print(f'{btype_idx2label[label]}: {count}')\n",
    "\n",
    "# 画出直方图\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(dev_label_counts)), [count for label, count in dev_label_counts_sorted])\n",
    "plt.title('Developer Type Label Distribution')\n",
    "plt.xlabel('Label_ID')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(btype_label_counts)), [count for label, count in btype_label_counts_sorted])\n",
    "plt.title('Bug Type Label Distribution')\n",
    "plt.xlabel('Label_ID')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# # 计算每个标签的出现次数\n",
    "# dev_label_counts = np.sum(y_dev_labels.numpy(), axis=0)\n",
    "# btype_label_counts = np.sum(y_btype_labels.numpy(), axis=0)\n",
    "\n",
    "# # 获取排序的索引\n",
    "# dev_sorted_indices = np.argsort(dev_label_counts)[::-1]\n",
    "# btype_sorted_indices = np.argsort(btype_label_counts)[::-1]\n",
    "\n",
    "# # 使用排序的索引来排序标签计数\n",
    "# dev_label_counts_sorted = dev_label_counts[dev_sorted_indices]\n",
    "# btype_label_counts_sorted = btype_label_counts[btype_sorted_indices]\n",
    "\n",
    "# # 绘制y_dev标签的分布图\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.bar(range(len(dev_label_counts_sorted)), dev_label_counts_sorted)\n",
    "# plt.title('y_dev Label Distribution')\n",
    "# plt.xlabel('Label_ID')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()\n",
    "\n",
    "# # 绘制y_btype标签的分布图\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.bar(range(len(btype_label_counts_sorted)), btype_label_counts_sorted)\n",
    "# plt.title('y_btype Label Distribution')\n",
    "# plt.xlabel('Label_ID')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3388fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386\n",
      "181\n"
     ]
    }
   ],
   "source": [
    "print(len(idx2label[0]))\n",
    "print(len(idx2label[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d38d4393-6258-471f-ae5b-b47bda48dab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "torch.Size([64, 300])\n",
      "torch.Size([64, 300])\n",
      "torch.Size([64, 386])\n",
      "torch.Size([64, 181])\n",
      "torch.Size([300])\n",
      "torch.Size([300])\n",
      "torch.Size([386])\n",
      "torch.Size([181])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "for data in train_loader:\n",
    "    (a, b), (c, d) = data\n",
    "    print(a.shape)\n",
    "    print(b.shape)\n",
    "    print(c.shape)\n",
    "    print(d.shape)\n",
    "    (a, b), (c, d) = train_dataset[0]\n",
    "    print(a.shape)\n",
    "    print(b.shape)\n",
    "    print(c.shape)\n",
    "    print(d.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b0a6bea1-398b-49f5-86a5-7eecbcd7dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testnan(name, x):\n",
    "    if torch.isnan(x).any():\n",
    "        print(name, x)\n",
    "\n",
    "def repnan(x):\n",
    "    return torch.where(torch.isnan(x), torch.ones_like(x), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "67b65f9c-fe89-4115-af2a-a8bead078227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO :训练的太快了，是不是参数太少了拟合不了？\n",
    "class MetaModel(nn.Module):\n",
    "    def __init__(self, vocab_size: list, emb_dim: int, seq_len: int, num_out: list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size: list, the size of C/A vocab\n",
    "            emb_dim: : int, the dim of C&A emb layer\n",
    "            seq_len:  MAX_SEQ_LEN\n",
    "            num_out: list, the output size of D/B\n",
    "        \"\"\"\n",
    "        super(MetaModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.num_out = num_out\n",
    "\n",
    "        self.context = nn.Sequential(\n",
    "            nn.Embedding(self.vocab_size[0], self.emb_dim),\n",
    "            nn.Conv1d(self.seq_len, 64, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(50, 1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.AST = nn.Sequential(\n",
    "            nn.Embedding(self.vocab_size[1], self.emb_dim),\n",
    "            nn.Conv1d(self.seq_len, 50, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(50, 100, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(50, 1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.BatchNorm1d(11172, affine=False),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(11172, 5000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(5000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_d = nn.Sequential(\n",
    "            nn.Linear(500, self.num_out[0]),\n",
    "            # nn.Softmax(dim=1),\n",
    "            # nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.fc_b = nn.Sequential(\n",
    "            nn.Linear(500, self.num_out[1]),\n",
    "            # nn.Softmax(dim=1),\n",
    "            # nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_C, x_A):\n",
    "        # x, y\n",
    "        x_C = self.context(x_C) \n",
    "        x_A = self.AST(x_A)\n",
    "        x = torch.concat((x_C, x_A), 1)\n",
    "        x = self.fc(x)\n",
    "        y_d = self.fc_d(x) \n",
    "        y_b = self.fc_b(x) \n",
    "        return y_d, y_b \n",
    "# class MetaModel(nn.Module):\n",
    "#     def __init__(self, vocab_size: list, emb_dim: int, seq_len: int, num_out: list):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             vocab_size: list, the size of C/A vocab\n",
    "#             emb_dim: : int, the dim of C&A emb layer\n",
    "#             seq_len:  MAX_SEQ_LEN\n",
    "#             num_out: list, the output size of D/B\n",
    "#         \"\"\"\n",
    "#         super(MetaModel, self).__init__()\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.emb_dim = emb_dim\n",
    "#         self.seq_len = seq_len\n",
    "#         self.num_out = num_out\n",
    "\n",
    "#         self.context = nn.Sequential(\n",
    "#             nn.Embedding(self.vocab_size[0], self.emb_dim),\n",
    "#             nn.Conv1d(self.seq_len, 64, kernel_size=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(99, 1),\n",
    "#             nn.Flatten(),\n",
    "#         )\n",
    "#         self.AST = nn.Sequential(\n",
    "#             nn.Embedding(self.vocab_size[1], self.emb_dim),\n",
    "#             # nn.LSTM(self.emb_dim, 25, batch_first=True, bidirectional=True),\n",
    "#             # nn.MaxPool1d(50, 1),\n",
    "#             nn.Conv1d(self.seq_len, 50, kernel_size=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(99, 1),\n",
    "#             nn.Flatten(),\n",
    "#         )\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.BatchNorm1d(114, affine=False), # one head\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(114, 50), # one head\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#         self.fc_d = nn.Sequential(\n",
    "#             nn.Linear(50, self.num_out[0]),\n",
    "#             nn.Sigmoid(),\n",
    "#         )\n",
    "\n",
    "#         self.fc_b = nn.Sequential(\n",
    "#             nn.Linear(50, self.num_out[1]),\n",
    "#             nn.Sigmoid(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x_C, x_A):\n",
    "#         # x, y\n",
    "#         x_C = self.context(x_C) \n",
    "#         x_A = self.AST(x_A) # one head\n",
    "#         x = torch.concat((x_C, x_A), 1) # one head\n",
    "#         x = self.fc(x) # one head\n",
    "#         y_d = self.fc_d(x) # one tail \n",
    "#         y_b = self.fc_b(x) # one tail \n",
    "#         return y_d, y_b # one tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "857339a6-b7e2-4ba1-84b7-66ba24e44375",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = len(train_loader) * EPOCH\n",
    "def get_lr_scheduler(optimizer):\n",
    "    return torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=Learning_Rate,\n",
    "        total_steps=N_STEPS,\n",
    "        pct_start=0.10,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=1e3,\n",
    "        final_div_factor=1e4,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d223154a-7742-4f56-a6f2-41efb97374ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# model\n",
    "model = MetaModel(vocab_size, EMB_DIM, MAX_SEQ_LEN, num_out).to(device)\n",
    "\n",
    "# loss_func\n",
    "# TODO: use loss functions for multi-label classification like focul loss or DBE\n",
    "# def loss_fn(y, y_pred):\n",
    "#     return -torch.sum(0.8*y*torch.log(y_pred) + 0.2*(1-y)*torch.log(1-y_pred))\n",
    "\n",
    "# class ClassBalancedFocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "#         super(ClassBalancedFocalLoss, self).__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.reduction = reduction\n",
    "\n",
    "#     def forward(self, target, input):\n",
    "#         # Convert one-hot encoded target to class labels\n",
    "#         target = torch.argmax(target, dim=1)\n",
    "#         # 计算每个类别的权重\n",
    "#         class_count = torch.bincount(target)\n",
    "#         total_count = target.numel()\n",
    "#         class_weights = 1.0 / (class_count.float() / total_count + 1e-6)\n",
    "\n",
    "#         # 计算Focal Loss\n",
    "#         ce_loss = F.cross_entropy(input, target, reduction='none')\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "\n",
    "#         # 应用类别权重\n",
    "#         class_weights = class_weights.to(input.device)\n",
    "#         weight = class_weights[target]\n",
    "#         balanced_focal_loss = weight * focal_loss\n",
    "\n",
    "#         if self.reduction == 'mean':\n",
    "#             return balanced_focal_loss.mean()\n",
    "#         elif self.reduction == 'sum':\n",
    "#             return balanced_focal_loss.sum()\n",
    "#         else:\n",
    "#             return balanced_focal_loss\n",
    "        \n",
    "# loss_fn = ClassBalancedFocalLoss(alpha=0.25, gamma=2.0, reduction='mean')\n",
    "# loss_fn = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "# loss_fn_mse = torch.nn.MSELoss().to(device)\n",
    "# loss_fn_ce = torch.nn.MultiLabelSoftMarginLoss().to(device)\n",
    "# loss_fn_ce = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "loss_name = 'BCELogits_Adam'\n",
    "# loss_func\n",
    "def loss_fn(y, y_pred):\n",
    "    return -torch.sum(0.8*y*torch.log(y_pred) + 0.2*(1-y)*torch.log(1-y_pred))\n",
    "\n",
    "# loss_name = 'CBFocalLoss_Adam'\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=Learning_Rate,\n",
    ")\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "LR_SCHEDULER = get_lr_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b7f2d108-7c52-4146-94d6-e25af7216b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y: torch.Tensor, pred: torch.Tensor, threshold_d, threshold_b, from_logits = True, split_pos = num_out):\n",
    "    if from_logits == True:\n",
    "        pred = nn.Sigmoid()(pred)\n",
    "    # pred = torch.where(y_pred > threshold, 1, 0)\n",
    "    y_d, y_b = torch.split(y, split_pos, dim=1)\n",
    "    pred_d, pred_b = torch.split(pred, split_pos, dim=1)\n",
    "\n",
    "    pred_d = torch.where(pred_d > threshold_d, 1, 0)\n",
    "    pred_b = torch.where(pred_b > threshold_b, 1, 0)\n",
    "    \n",
    "    # print(y_d,pred_d)\n",
    "    TPd, TPb = torch.sum(y_d * pred_d, dim=1), torch.sum(y_b * pred_b, dim=1)\n",
    "    TNd, TNb = torch.sum((1-y_d) * (1-pred_d), dim=1), torch.sum((1-y_b) * (1-pred_b), dim=1)\n",
    "    FPd, FPb = torch.sum((1-y_d) * pred_d , dim=1), torch.sum((1-y_b) * pred_b , dim=1)\n",
    "    FNd, FNb = torch.sum(y_d * (1-pred_d), dim=1), torch.sum(y_b * (1-pred_b), dim=1)\n",
    "\n",
    "    acc = torch.mean((TPd + TNd) / (TPd + TNd + FPd + FNd + 1e-6)).item(), torch.mean((TPb + TNb) / (TPb + TNb + FPb + FNb + 1e-6)).item()\n",
    "    recall = torch.mean(TPd / (TPd + FNd + 1e-6)).item(), torch.mean(TPb / (TPb + FNb + 1e-6)).item()\n",
    "    precision = torch.mean(TPd / (TPd + FPd + 1e-6)).item(), torch.mean(TPb / (TPb + FPb + 1e-6)).item()\n",
    "    F1 = 2 * recall[0] * precision[0] / (recall[0] + precision[0] + 1e-6), 2 * recall[1] * precision[1] / (recall[1] + precision[1] + 1e-6)\n",
    "    \n",
    "    return {\n",
    "        'acc': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'F1': F1\n",
    "    }\n",
    "\n",
    "def one_forward(data):\n",
    "    (x_context, x_AST), (y_dev, y_btype) = data\n",
    "    y_dev_pred, y_btype_pred = model(x_context.long().to(device), x_AST.long().to(device)) \n",
    "    \n",
    "    y = torch.concat((y_dev, y_btype), 1).to(device) \n",
    "    y_pred = torch.concat((y_dev_pred, y_btype_pred), 1) \n",
    "\n",
    "    # loss = Weight_MSE * loss_fn_mse(y, nn.Sigmoid()(y_pred)) + Weight_BCE * loss_fn_ce(y, y_pred)\n",
    "    loss = loss_fn(y, y_pred)\n",
    "    metric = metrics(y, y_pred, from_logits=False, split_pos=num_out, threshold_d=0.62,threshold_b=0.58)\n",
    "    \n",
    "    return loss, metric['acc'], metric['precision'], metric['recall'], metric['F1']\n",
    "\n",
    "\n",
    "def one_backward(optimizer, loss):\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # Gradient clipping\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "def one_train_scaler(scaler, data, optimizer):\n",
    "    with torch.cuda.amp.autocast():\n",
    "        optimizer.zero_grad()\n",
    "        loss, acc, precision, recall, f1 = one_forward(data)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2ece2862-3ec4-47ca-b60a-b910bbfb06ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[386, 181]\n"
     ]
    }
   ],
   "source": [
    "print(num_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6d68510f-1e9e-4757-bec6-a561e696f882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'pred' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m---> 12\u001b[0m     loss, acc, precision, recall, f1 \u001b[38;5;241m=\u001b[39m \u001b[43mone_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     one_backward(optimizer, loss)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# one_train_scaler(scaler, data, optimizer)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# LR_SCHEDULER.step()\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# val\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[105], line 39\u001b[0m, in \u001b[0;36mone_forward\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# loss = Weight_MSE * loss_fn_mse(y, nn.Sigmoid()(y_pred)) + Weight_BCE * loss_fn_ce(y, y_pred)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y, y_pred)\n\u001b[1;32m---> 39\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold_d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.62\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mthreshold_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.58\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, metric[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m], metric[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m], metric[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m], metric[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[105], line 7\u001b[0m, in \u001b[0;36mmetrics\u001b[1;34m(y, y_pred, threshold_d, threshold_b, from_logits, split_pos)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# pred = torch.where(y_pred > threshold, 1, 0)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m y_d, y_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(y, split_pos, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m pred_d, pred_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(\u001b[43mpred\u001b[49m, split_pos, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m pred_d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(pred_d \u001b[38;5;241m>\u001b[39m threshold_d, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     10\u001b[0m pred_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(pred_b \u001b[38;5;241m>\u001b[39m threshold_b, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'pred' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "writer = SummaryWriter('./tf-logs')\n",
    "for epoch in tqdm.trange(EPOCH):\n",
    "\n",
    "    # train\n",
    "    model.train()\n",
    "    for step, data in enumerate(train_loader):\n",
    "\n",
    "        loss, acc, precision, recall, f1 = one_forward(data)\n",
    "        one_backward(optimizer, loss)\n",
    "        \n",
    "        # one_train_scaler(scaler, data, optimizer)\n",
    "        # LR_SCHEDULER.step()\n",
    "        \n",
    "\n",
    "    # val\n",
    "    model.eval()\n",
    "    val_loss, val_acc, val_precision, val_recall, val_F1 = 0, [0, 0], [0, 0], [0, 0], [0, 0]\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(test_loader):\n",
    "            loss, acc, precision, recall, f1 = one_forward(data)\n",
    "            l = len(test_loader)\n",
    "            val_loss += loss.item() / l\n",
    "            val_acc[0] += acc[0]/l\n",
    "            val_acc[1] += acc[1]/l\n",
    "            val_precision[0] += precision[0]/l\n",
    "            val_precision[1] += precision[1]/l\n",
    "            val_recall[0] += recall[0]/l\n",
    "            val_recall[1] += recall[1]/l\n",
    "            val_F1[0] += f1[0]/l \n",
    "            val_F1[1] += f1[1]/l \n",
    "            \n",
    "    # print('{}th epoch\\n val_loss: {}\\n val_acc:{}\\n val_precision:{}\\n val_recall:{}\\n val_f1: {}'.format(epoch, val_loss, val_acc, val_precision, val_recall, val_F1))\n",
    "    writer.add_scalar('val_loss'+loss_name+str(Learning_Rate), val_loss, epoch)\n",
    "    writer.add_scalar('val_acc_d'+loss_name+str(Learning_Rate), val_acc[0], epoch)\n",
    "    writer.add_scalar('val_acc_b'+loss_name+str(Learning_Rate), val_acc[1], epoch)\n",
    "    # writer.add_scalar('val_precision'+loss_name+str(Learning_Rate), val_precision, epoch)\n",
    "    # writer.add_scalar('val_recall'+loss_name+str(Learning_Rate), val_recall, epoch)\n",
    "    writer.add_scalar('val_f1_d'+loss_name+str(Learning_Rate), val_F1[0], epoch)\n",
    "    writer.add_scalar('val_f1_b'+loss_name+str(Learning_Rate), val_F1[1], epoch)\n",
    "\n",
    "    # save model\n",
    "    # if epoch % 20 == 0:\n",
    "        # torch.save(model, '../savedmodel/model_epoch{}.pth'.format(epoch))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3dc805-a62b-4d60-ad60-0b4a91c96d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan]], grad_fn=<SigmoidBackward0>) tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]]) tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "(x_c, x_a), (y_d, y_b) = test_dataset[0]\n",
    "x_c = torch.reshape(x_c.long().to(device), (1, 300))\n",
    "x_a = torch.reshape(x_a.long().to(device), (1, 300))\n",
    "y_d_pred, y_b_pred = model(x_c, x_a)\n",
    "\n",
    "y_d_pred, y_b_pred = nn.Sigmoid()(y_d_pred), nn.Sigmoid()(y_b_pred)\n",
    "print(y_d_pred, y_b_pred)\n",
    "# print(y_d_pred[0][-29])\n",
    "#TODO: 调整阈值\n",
    "#TODO: 多标签分类问题：换用F1分数、Hamming损失或Jaccard相似度\n",
    "print(torch.where(y_d_pred > 0.62, 1.0, 0.0), torch.where(y_b_pred > 0.58, 1.0, 0.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da67242-c892-4e93-8fc6-831e6409438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0.])\n"
     ]
    }
   ],
   "source": [
    "print(y_d,y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09476b14-ee4a-4ccd-98f7-15b137752a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[386, 181]\n"
     ]
    }
   ],
   "source": [
    "print(num_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
